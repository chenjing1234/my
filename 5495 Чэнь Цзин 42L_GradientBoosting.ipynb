{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StcWwKvBKBeQ"
   },
   "source": [
    "# Градиентный бустинг\n",
    "\n",
    "Мы возвращаемся на титаник, но уже с новым инструментом!\n",
    "\n",
    "**Большая задача** этой лабораторной - произведите исследование метода градиентного бустинга для классификации [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), как мы изучали метод случайного леса.\n",
    "\n",
    "1. Давайте пройдемся по основным моментам:\n",
    "- начните с разработки baseline модели,\n",
    "- далее проверьте влияние гиперпараметров на результат работы модели,\n",
    "- проведите расширенный анализ данных (дополнительная обработка - чистка, новые признаки и т.д.) и оцените работу модели;\n",
    "- поиском определите лучшую модель;\n",
    "\n",
    "2. Далее сравниваем работу моделей (леса и бустинга) при их лучших гиперпараметрах по показателям на тестовой выборке (*hold-out*).\n",
    "\n",
    "> Помним, что поиск лучших гиперпараметров производится кросс-валидацией на обучающей выборке!\n",
    "\n",
    "3. Напоследок, установите фреймворки [XGBoost](https://xgboost.readthedocs.io/en/latest/) и [LightGBM](https://lightgbm.readthedocs.io/en/latest/), а после этого разберитесь с тем, как создать объекты моделей и с помощью уже известных инструментов найдите лучшие гиперпараметры. \n",
    "\n",
    "В результаты должна получиться табличка сравнения, в которой отражены показатели моделей:\n",
    "- RandomForestClassifier;\n",
    "- GradientBoostingClassifier;\n",
    "- XGBoost;\n",
    "- LightGBM.\n",
    "\n",
    "Для каждой лучшей модели постройте матрицу ошибок, отобразите результаты и проведите анализ ошибок одной из моделей бустинга (лучшей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Xtqo-7JsUMj"
   },
   "source": [
    "\n",
    "В качестве выводов напишите:\n",
    "- В чем разница моделей бустинга?\n",
    "- За что отвечает каждый гиперпараметр моделей бустинга?\n",
    "- В каких случаях лучше применять один или другой метод бустинга или случайнй лес?\n",
    "- Какой еще актуальный метод бустинга существует сегодня (от Яндекса)? В чем его преимущества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra3t6o7zAdcd"
   },
   "source": [
    "(1)импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "titanic = pd.read_csv('C:\\ml_edu-master\\datasets\\Titanic_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)Выбор функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic[['Pclass', 'Age', 'Sex']]\n",
    "y = titanic['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)Очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Age'].fillna(X['Age'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)Разделите тренировочный набор тестовый набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5)Функции преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Pclass', 'Sex=female', 'Sex=male']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "print(vec.feature_names_)\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6)Моделирование и тестирование производительности\n",
    "\n",
    "① Единое дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8340807174887892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.90      0.84      0.87       143\n",
      "    survived       0.74      0.82      0.78        80\n",
      "\n",
      "    accuracy                           0.83       223\n",
      "   macro avg       0.82      0.83      0.82       223\n",
      "weighted avg       0.84      0.83      0.84       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "y_predict = dtc.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(dtc.score(X_test, y_test))\n",
    "print(classification_report(y_predict, y_test, target_names = ['died', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "②Дерево решений градиентного подъема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8430493273542601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.91      0.84      0.87       145\n",
      "    survived       0.74      0.85      0.79        78\n",
      "\n",
      "    accuracy                           0.84       223\n",
      "   macro avg       0.83      0.84      0.83       223\n",
      "weighted avg       0.85      0.84      0.85       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc=GradientBoostingClassifier()\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_y_prde=gbc.predict(X_test)\n",
    "print(gbc.score(X_test, y_test))\n",
    "print(classification_report(gbc_y_prde, y_test, target_names = ['died', 'survived']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните лес случайных решений и способность модели XGBoost предсказать выживут ли пассажиры на Титанике："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest Classifier on testing set: 0.8340807174887892\n"
     ]
    }
   ],
   "source": [
    "X = titanic[['Pclass', 'Age', 'Sex']]\n",
    "y = titanic['Survived']\n",
    "X['Age'].fillna(X['Age'].mean(), inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 33)\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse=False)\n",
    "X_train = vec.fit_transform(X_train.to_dict(orient='record'))\n",
    "X_test = vec.transform(X_test.to_dict(orient='record'))\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "print ( \"The accuracy of Random Forest Classifier on testing set:\", rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The accuracy of eXtreme Gradient Boosting Classifier on testing set: 0.8251121076233184\n"
     ]
    }
   ],
   "source": [
    "# Предсказать тот же набор тестов с настроенной по умолчанию моделью XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgbc = XGBClassifier(learning_rate=0.1)\n",
    "xgbc.fit(X_train, y_train)\n",
    "print ('The accuracy of eXtreme Gradient Boosting Classifier on testing set:', xgbc.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab4_GB.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
